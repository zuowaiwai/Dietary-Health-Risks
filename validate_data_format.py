#!/usr/bin/env python3
"""
validate_data_format.py

å¿«é€Ÿæ•°æ®æ ¼å¼éªŒè¯è„šæœ¬
ç”¨äºåœ¨è¿è¡Œä¸»åˆ†æå‰æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
"""

import pandas as pd
import os
from pathlib import Path
import argparse
import sys

def validate_variable_dictionary(dict_path: str) -> bool:
    """éªŒè¯å˜é‡å­—å…¸æ ¼å¼"""
    print(f"ğŸ” æ£€æŸ¥å˜é‡å­—å…¸: {dict_path}")
    
    if not os.path.exists(dict_path):
        print(f"âŒ é”™è¯¯: å˜é‡å­—å…¸æ–‡ä»¶ä¸å­˜åœ¨: {dict_path}")
        return False
    
    try:
        df = pd.read_csv(dict_path)
        print(f"âœ… æˆåŠŸåŠ è½½å˜é‡å­—å…¸ï¼Œå…± {len(df)} è¡Œ")
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_cols = ['global_variable_id', 'file_name', 'variable_name', 'category']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            print(f"âŒ é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_cols}")
            print(f"   å®é™…åˆ—å: {list(df.columns)}")
            return False
        
        print(f"âœ… åŒ…å«æ‰€æœ‰å¿…éœ€çš„åˆ—: {required_cols}")
        
        # æ£€æŸ¥Bå’ŒB&Cç±»å‹å˜é‡
        b_vars = df[df['category'].isin(['B', 'B&C'])]
        print(f"âœ… æ‰¾åˆ° {len(b_vars)} ä¸ªB/B&Cç±»å‹å˜é‡")
        
        if len(b_vars) == 0:
            print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°Bæˆ–B&Cç±»å‹çš„å˜é‡")
            return False
        
        # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
        category_counts = df['category'].value_counts()
        print("ğŸ“Š å˜é‡ç±»å‹åˆ†å¸ƒ:")
        for cat, count in category_counts.head(10).items():
            print(f"   {cat}: {count}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å˜é‡å­—å…¸: {e}")
        return False

def validate_data_directory(data_dir: str, variable_dict: pd.DataFrame = None) -> bool:
    """éªŒè¯æ•°æ®ç›®å½•æ ¼å¼"""
    print(f"\nğŸ” æ£€æŸ¥æ•°æ®ç›®å½•: {data_dir}")
    
    data_path = Path(data_dir)
    if not data_path.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = list(data_path.glob("*.csv"))
    print(f"âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    if len(csv_files) == 0:
        print("âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸­æ²¡æœ‰CSVæ–‡ä»¶")
        return False
    
    # æ£€æŸ¥å‡ ä¸ªæ ·æœ¬æ–‡ä»¶
    sample_files = csv_files[:3]  # æ£€æŸ¥å‰3ä¸ªæ–‡ä»¶
    print(f"\nğŸ“‹ æ£€æŸ¥æ ·æœ¬æ–‡ä»¶æ ¼å¼ï¼ˆå‰{len(sample_files)}ä¸ªï¼‰:")
    
    for file_path in sample_files:
        print(f"\n  ğŸ” æ£€æŸ¥æ–‡ä»¶: {file_path.name}")
        
        try:
            # åªè¯»å–å‰å‡ è¡Œæ£€æŸ¥æ ¼å¼
            sample = pd.read_csv(file_path, nrows=5)
            print(f"    âœ… å½¢çŠ¶: {sample.shape}")
            print(f"    âœ… åˆ—æ•°: {len(sample.columns)}")
            print(f"    âœ… ç¬¬ä¸€åˆ—: {sample.columns[0]}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«IDåˆ—
            first_col = sample.columns[0]
            if 'sequence' in first_col.lower() or 'seqn' in first_col.lower():
                print(f"    âœ… IDåˆ—è¯†åˆ«æ­£ç¡®")
            else:
                print(f"    âš ï¸  è­¦å‘Š: ç¬¬ä¸€åˆ—å¯èƒ½ä¸æ˜¯IDåˆ—")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            id_values = sample.iloc[:, 0].dropna()
            if len(id_values) > 0:
                print(f"    âœ… æ ·æœ¬IDå€¼: {id_values.iloc[0]}")
            
        except Exception as e:
            print(f"    âŒ é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {file_path.name}: {e}")
            return False
    
    # å¦‚æœæœ‰å˜é‡å­—å…¸ï¼Œæ£€æŸ¥æ–‡ä»¶å¯¹åº”å…³ç³»
    if variable_dict is not None:
        print(f"\nğŸ”— æ£€æŸ¥æ–‡ä»¶å¯¹åº”å…³ç³»:")
        b_vars = variable_dict[variable_dict['category'].isin(['B', 'B&C'])]
        file_names = set(b_vars['file_name'].unique())
        existing_files = set([f.name for f in csv_files])
        
        missing_files = file_names - existing_files
        if missing_files:
            print(f"    âš ï¸  è­¦å‘Š: å˜é‡å­—å…¸ä¸­æåˆ°ä½†æ–‡ä»¶ä¸å­˜åœ¨çš„æ–‡ä»¶:")
            for fname in sorted(list(missing_files))[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"      - {fname}")
        else:
            print(f"    âœ… æ‰€æœ‰å¿…éœ€çš„æ•°æ®æ–‡ä»¶éƒ½å­˜åœ¨")
    
    return True

def validate_sample_variable_loading(dict_path: str, data_dir: str) -> bool:
    """éªŒè¯æ ·æœ¬å˜é‡åŠ è½½"""
    print(f"\nğŸ§ª æµ‹è¯•æ ·æœ¬å˜é‡åŠ è½½:")
    
    try:
        # è¯»å–å˜é‡å­—å…¸
        var_dict = pd.read_csv(dict_path)
        b_vars = var_dict[var_dict['category'].isin(['B', 'B&C'])]
        
        if len(b_vars) == 0:
            print("âŒ æ²¡æœ‰B/B&Cç±»å‹å˜é‡å¯æµ‹è¯•")
            return False
        
        # æµ‹è¯•åŠ è½½å‰å‡ ä¸ªå˜é‡
        test_vars = b_vars.head(3)
        data_path = Path(data_dir)
        
        for idx, var_info in test_vars.iterrows():
            file_path = data_path / var_info['file_name']
            var_name = var_info['variable_name']
            
            print(f"  ğŸ” æµ‹è¯•å˜é‡: {var_name}")
            print(f"    æ–‡ä»¶: {var_info['file_name']}")
            
            if not file_path.exists():
                print(f"    âŒ æ–‡ä»¶ä¸å­˜åœ¨")
                continue
            
            try:
                # è¯»å–è¡¨å¤´
                header = pd.read_csv(file_path, nrows=0)
                columns = header.columns.tolist()
                
                if var_name not in columns:
                    print(f"    âŒ å˜é‡ä¸åœ¨æ–‡ä»¶ä¸­")
                    print(f"    å¯ç”¨åˆ—: {columns[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªåˆ—å
                    continue
                
                # å°è¯•åŠ è½½è¯¥å˜é‡
                id_col = columns[0]
                data = pd.read_csv(file_path, usecols=[id_col, var_name], nrows=100)
                
                print(f"    âœ… æˆåŠŸåŠ è½½ï¼Œå½¢çŠ¶: {data.shape}")
                print(f"    âœ… ç¼ºå¤±ç‡: {data[var_name].isna().mean():.2%}")
                
                valid_values = data[var_name].dropna()
                if len(valid_values) > 0:
                    print(f"    âœ… æ ·æœ¬å€¼: {valid_values.iloc[0]}")
                
            except Exception as e:
                print(f"    âŒ åŠ è½½å¤±è´¥: {e}")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='éªŒè¯NHANESæ•°æ®æ ¼å¼')
    parser.add_argument('--variable_dict', type=str, 
                       default='all_nhanes_variables.csv',
                       help='å˜é‡å­—å…¸æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_dir', type=str,
                       default='NHANES_PROCESSED_CSV_merged_by_prefix',
                       help='æ•°æ®æ–‡ä»¶ç›®å½•')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ” NHANESæ•°æ®æ ¼å¼éªŒè¯")
    print("="*60)
    
    all_passed = True
    
    # 1. éªŒè¯å˜é‡å­—å…¸
    dict_valid = validate_variable_dictionary(args.variable_dict)
    all_passed = all_passed and dict_valid
    
    # 2. éªŒè¯æ•°æ®ç›®å½•
    var_dict = None
    if dict_valid:
        var_dict = pd.read_csv(args.variable_dict)
    
    dir_valid = validate_data_directory(args.data_dir, var_dict)
    all_passed = all_passed and dir_valid
    
    # 3. æµ‹è¯•æ ·æœ¬å˜é‡åŠ è½½
    if dict_valid and dir_valid:
        load_valid = validate_sample_variable_loading(args.variable_dict, args.data_dir)
        all_passed = all_passed and load_valid
    
    print("\n" + "="*60)
    if all_passed:
        print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¿è¡Œä¸»åˆ†æè„šæœ¬ã€‚")
        print("\nğŸš€ è¿è¡Œä¸»åˆ†æçš„å‘½ä»¤:")
        print(f"python modularize_mediators_iteratively.py --variable_dict {args.variable_dict} --data_dir {args.data_dir}")
    else:
        print("âŒ éªŒè¯å¤±è´¥ï¼è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åå†è¿è¡Œä¸»åˆ†æè„šæœ¬ã€‚")
        sys.exit(1)
    
    print("="*60)

if __name__ == "__main__":
    main() 