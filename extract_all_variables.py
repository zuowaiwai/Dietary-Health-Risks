#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æå–æ‰€æœ‰NHANESåˆå¹¶CSVæ–‡ä»¶çš„å˜é‡å
========================================

æ­¤è„šæœ¬è¯»å–æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰CSVæ–‡ä»¶çš„åˆ—åï¼Œå¹¶æ±‡æ€»åˆ°ä¸€ä¸ªCSVæ–‡ä»¶ä¸­ã€‚
é¿å…åŠ è½½å®Œæ•´æ•°æ®ï¼Œåªè¯»å–åˆ—åä»¥èŠ‚çœå†…å­˜ã€‚

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024å¹´
"""

import pandas as pd
import os
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('variable_extraction.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def extract_all_variables(input_dir, output_file):
    """
    æå–æ‰€æœ‰CSVæ–‡ä»¶çš„å˜é‡å
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
    """
    input_path = Path(input_dir)
    
    if not input_path.exists():
        logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return False
    
    # å­˜å‚¨æ‰€æœ‰å˜é‡ä¿¡æ¯
    all_variables = []
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = list(input_path.glob("*.csv"))
    logger.info(f"å‘ç° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    for csv_file in csv_files:
        try:
            logger.info(f"å¤„ç†æ–‡ä»¶: {csv_file.name}")
            
            # åªè¯»å–ç¬¬ä¸€è¡Œæ¥è·å–åˆ—åï¼Œé¿å…å†…å­˜é—®é¢˜
            df_header = pd.read_csv(csv_file, nrows=0)
            columns = df_header.columns.tolist()
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size_mb = csv_file.stat().st_size / (1024 * 1024)
            
            # ä¸ºæ¯ä¸ªå˜é‡åˆ›å»ºè®°å½•
            for col_index, col_name in enumerate(columns):
                variable_info = {
                    'file_name': csv_file.name,
                    'file_size_mb': round(file_size_mb, 2),
                    'variable_index': col_index,
                    'variable_name': col_name,
                    'dataset_category': csv_file.stem.replace('_merged', ''),
                }
                all_variables.append(variable_info)
            
            logger.info(f"  âœ… æå–äº† {len(columns)} ä¸ªå˜é‡")
            
        except Exception as e:
            logger.error(f"  âŒ å¤„ç†æ–‡ä»¶ {csv_file.name} æ—¶å‡ºé”™: {e}")
            continue
    
    # åˆ›å»ºæ±‡æ€»DataFrame
    if all_variables:
        variables_df = pd.DataFrame(all_variables)
        
        # æŒ‰æ–‡ä»¶åå’Œå˜é‡ç´¢å¼•æ’åº
        variables_df = variables_df.sort_values(['file_name', 'variable_index'])
        
        # æ·»åŠ å…¨å±€å˜é‡ç¼–å·
        variables_df['global_variable_id'] = range(1, len(variables_df) + 1)
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        column_order = [
            'global_variable_id',
            'file_name', 
            'dataset_category',
            'file_size_mb',
            'variable_index',
            'variable_name'
        ]
        variables_df = variables_df[column_order]
        
        # ä¿å­˜åˆ°CSV
        variables_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        summary_stats = {
            'total_files': len(csv_files),
            'total_variables': len(variables_df),
            'files_processed': variables_df['file_name'].nunique(),
            'largest_file': variables_df.loc[variables_df['file_size_mb'].idxmax()],
            'most_variables_file': variables_df.groupby('file_name').size().idxmax(),
            'variables_by_file': variables_df.groupby('file_name').size().to_dict()
        }
        
        logger.info("="*60)
        logger.info("ğŸ“Š å˜é‡æå–å®Œæˆç»Ÿè®¡:")
        logger.info(f"   ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {summary_stats['files_processed']}/{summary_stats['total_files']}")
        logger.info(f"   ğŸ”¢ æ€»å˜é‡æ•°: {summary_stats['total_variables']:,}")
        logger.info(f"   ğŸ“ˆ æœ€å¤§æ–‡ä»¶: {summary_stats['largest_file']['file_name']} ({summary_stats['largest_file']['file_size_mb']:.1f} MB)")
        logger.info(f"   ğŸ“‹ å˜é‡æœ€å¤šæ–‡ä»¶: {summary_stats['most_variables_file']} ({summary_stats['variables_by_file'][summary_stats['most_variables_file']]} ä¸ªå˜é‡)")
        logger.info(f"   ğŸ’¾ ç»“æœä¿å­˜è‡³: {output_file}")
        logger.info("="*60)
        
        # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
        summary_file = str(output_file).replace('.csv', '_summary.txt')
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("NHANESå˜é‡æå–ç»Ÿè®¡æ‘˜è¦\n")
            f.write("="*50 + "\n")
            f.write(f"å¤„ç†æ—¶é—´: {pd.Timestamp.now()}\n")
            f.write(f"è¾“å…¥ç›®å½•: {input_dir}\n")
            f.write(f"è¾“å‡ºæ–‡ä»¶: {output_file}\n\n")
            f.write(f"æ–‡ä»¶å¤„ç†æƒ…å†µ:\n")
            f.write(f"  - å‘ç°æ–‡ä»¶æ•°: {summary_stats['total_files']}\n")
            f.write(f"  - æˆåŠŸå¤„ç†: {summary_stats['files_processed']}\n")
            f.write(f"  - å¤±è´¥/è·³è¿‡: {summary_stats['total_files'] - summary_stats['files_processed']}\n\n")
            f.write(f"å˜é‡ç»Ÿè®¡:\n")
            f.write(f"  - æ€»å˜é‡æ•°: {summary_stats['total_variables']:,}\n")
            f.write(f"  - å¹³å‡æ¯æ–‡ä»¶å˜é‡æ•°: {summary_stats['total_variables']/summary_stats['files_processed']:.1f}\n\n")
            f.write(f"å„æ–‡ä»¶å˜é‡æ•°ç»Ÿè®¡:\n")
            for file_name, var_count in sorted(summary_stats['variables_by_file'].items()):
                f.write(f"  - {file_name}: {var_count} ä¸ªå˜é‡\n")
        
        return True
    else:
        logger.error("âŒ æœªèƒ½æå–åˆ°ä»»ä½•å˜é‡")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” NHANESå˜é‡åæå–å·¥å…·")
    print("="*50)
    
    # è®¾ç½®è·¯å¾„
    input_directory = "./Nhanes_processed_csv_merged"
    output_csv = "all_nhanes_variables.csv"
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not Path(input_directory).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_directory}")
        print("è¯·ç¡®ä¿ç›®å½•è·¯å¾„æ­£ç¡®")
        return
    
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_directory}")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_csv}")
    print("-"*50)
    
    # æ‰§è¡Œæå–
    success = extract_all_variables(input_directory, output_csv)
    
    if success:
        print("\nâœ… å˜é‡æå–æˆåŠŸå®Œæˆ!")
        print(f"ğŸ“Š æ‰€æœ‰å˜é‡ä¿¡æ¯å·²ä¿å­˜è‡³: {output_csv}")
        print("ğŸ’¡ æç¤º: å¯ä»¥ç”¨Excelæˆ–å…¶ä»–å·¥å…·æ‰“å¼€æŸ¥çœ‹ç»“æœ")
    else:
        print("\nâŒ å˜é‡æå–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        print("ğŸ“ è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ variable_extraction.log è·å–è¯¦ç»†ä¿¡æ¯")

if __name__ == "__main__":
    main() 